{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Feature Extraction\n",
    "\n",
    "This script provides a function that extracts features <br>\n",
    "\n",
    "\n",
    "*Input:*  \n",
    "- executionMode_dict\n",
    "- mode               -> ('production' / 'sample')\n",
    "- model              -> ('train' / 'test')\n",
    "- print_status       -> (True / False)\n",
    "- sentence_limit = None  (limit of sentences to import (default: None)\n",
    "\n",
    "*Output:* \n",
    "- executionMode_dict \n",
    "\n",
    "\n",
    "*List of additionally extracted features:* \n",
    "- Constituents\n",
    "- Active / Passive \n",
    "- ..\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(executionMode_dict,\n",
    "                    mode,                   #('production' / 'sample')\n",
    "                    model,                  #('train' / 'test')\n",
    "                    print_status   = False,\n",
    "                    sentence_limit = None):\n",
    "    \n",
    "\n",
    "    path_to_input = executionMode_dict[mode]['intermediate'][model]['03_convertedDataframe']\n",
    "    path_to_save = '../data/intermediate/' + mode + '_' + model +'_04_ExtractedFeatures.csv'\n",
    "    executionMode_dict[mode]['intermediate'][model]['04_FeaturesExtracted'] = path_to_save\n",
    "    \n",
    "    # read dataframe in\n",
    "    df = pd.read_csv(path_to_input)\n",
    "    \n",
    "    display(df.head(5))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## insert here\n",
    "    \n",
    "    \n",
    "    df = df
    
         df['passive'] = np.nan
         df['full_constituent'] = np.nan

         # loop through sentences
         for s_id in df.sentenceId.unique():

             # filter for only this sentence
             df_sentence = df[df.sentenceId == s_id]

             # loop through each repetition
             for s_rep in df_sentence.sentenceRepetition.unique():

                 # create new subframe for working within this repetition of sentence
                 df_sentence_repetition = df_sentence[df_sentence.sentenceRepetition == s_rep]
                 #print(df_sentence_repetition.index)

         # to extract voice of phrase/sentence (a boolean value for passive)
                 for (pred, dep, voice) in zip(df_sentence_repetition['predicate_prediction'], df_sentence_repetition['dep'], df_sentence_repetition['morph']):
                     if pred == True and 'Voice=Pass' in voice or pred == True and 'pass' in dep:
                         df_sentence_repetition.passive = True
                         df.loc[df_sentence_repetition.index, 'passive'] = True # uncomment # I used .loc since otherwise it did not work for the final df plus I got a
                     elif pred == True and 'Voice=Pass' not in voice or pred == True and 'pass' not in dep:
                         df_sentence_repetition.passive = False
                         df.loc[df_sentence_repetition.index, 'passive'] = False

         # to establish the full constituent for each token
                 nlp = spacy.load("en_core_web_sm")
                 sentence = [] 
                 for (ind, ident, token, pos) in (zip(df_sentence_repetition.index, df_sentence_repetition['id'], df_sentence_repetition['form'], df_sentence_repetition['upos'])):
                     sentence.append(token)

                 sent = ' '.join(sentence)
                 doc = nlp(sent)

                 count_df = 0
                 for ind in df_sentence_repetition.index:        
                     count_doc = 0
                     count_df = count_df + 1
                     for s in doc.sents:
                         for t in s:
                             count_doc = count_doc + 1
                             if count_df == count_doc:
                                 full_const = list(t.subtree)
                                 full_c = ' '.join(map(str, full_const))
                                 full_c = re.sub(r'\s+([?.!"])', r'\1', full_c)
                                 df_sentence_repetition.loc[ind, 'full_constituent'] = full_c
                                 df.loc[ind, 'full_constituent'] = full_c\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #write dataframe out\n",
    "    df.to_csv(path_to_save, index=False)\n",
    "    \n",
    "    \n",
    "    if print_status == True:\n",
    "        \n",
    "        print('\\n\\n#### 4 Feature Extraction ####\\n\\n')\n",
    "        \n",
    "        print(' Features extracted:')\n",
    "        #list features\n",
    "        print(' - Constituents')\n",
    "        print(' - Passive / Active')\n",
    "        print(' - ...')\n",
    "        print('\\n - completed')\n",
    "    \n",
    "    return executionMode_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
