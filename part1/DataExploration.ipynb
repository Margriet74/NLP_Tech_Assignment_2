{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "#path_train = '../data/input/srl_univprop_en.train.conll'\n",
    "#path_dev   = '../data/input/srl_univprop_en.dev.conll'\n",
    "path_example   = '../data/input/srl_univprop_en.example.conll'\n",
    "\n",
    "path_train = '../data/input/en_ewt-up-train.conllu' \n",
    "path_test  = '../data/input/en_ewt-up-test.conllu'\n",
    "path_dev   = '../data/input/en_ewt-up-dev.conllu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_line_length = 15\n",
    "\n",
    "def printLines(path):\n",
    "\n",
    "    # first exploration\n",
    "    c = 0\n",
    "    with open(path) as file:\n",
    "        '''for line in file:\n",
    "            print(line)\n",
    "            c += 1\n",
    "\n",
    "            if c >= 10:\n",
    "                break\n",
    "        '''\n",
    "        sentences = 0\n",
    "        for line in file:\n",
    "\n",
    "                # pass all other lines\n",
    "                if line.startswith('# text'):\n",
    "                    sentences += 1\n",
    "\n",
    "                elif line.startswith('#') or line.startswith('\\n'):\n",
    "                    pass\n",
    "\n",
    "                # only go into token lines\n",
    "                else:\n",
    "\n",
    "                    # omit linebreaks from some lines\n",
    "                    if line.endswith('\\n'):\n",
    "                        line = line.replace('\\n', '')\n",
    "\n",
    "                    # split input line\n",
    "                    values = np.array(line.split('\\t'))\n",
    "                    print(values)\n",
    "\n",
    "                    array  = np.full(max_line_length+1, np.str)\n",
    "                    \n",
    "                    # add sentenceId\n",
    "                    array[0] = sentences\n",
    "                    # add retrieved information from conll file\n",
    "                    array[1:len(values)+1] = values\n",
    "                    # fill remaining columns   !!** use np.nan ?! **!! \n",
    "                    array[len(values) +1:] = '_'\n",
    "                    \n",
    "                    print(array)\n",
    "                    \n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srl_univprop_en.dev.conll\n",
      ".DS_Store\n",
      "srl_univprop_en.example.conll\n",
      "en_ewt-up-test.conllu\n",
      "srl_univprop_en.train.conll\n",
      "en_ewt-up-dev.conllu\n",
      "en_ewt-up-train.conllu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = os.fsencode('../data/input/')\n",
    "    \n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' 'Really' 'really' 'ADV' 'RB' '_' '2' 'advmod' '2:advmod' '_' '_'\n",
      " 'ARGM-EXT']\n",
      "[1 '1' 'Really' 'really' 'ADV' 'RB' '_' '2' 'advmod' '2:advmod' '_' '_'\n",
      " 'ARGM-EXT' '_' '_' '_']\n",
      "\n",
      "#######\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printLines(path_example)\n",
    "\n",
    "print('\\n#######\\n')\n",
    "\n",
    "#printLines(path_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conll Description\n",
    "\n",
    "\"Sentences consist of one or more word lines, and word lines contain the following fields:\n",
    "\n",
    "ID: Word index, integer starting at 1 for each new sentence; may be a range for multiword tokens; may be a decimal number for empty nodes (decimal numbers can be lower than 1 but must be greater than 0). <br>\n",
    "FORM: Word form or punctuation symbol. <br>\n",
    "LEMMA: Lemma or stem of word form. <br>\n",
    "UPOS: Universal part-of-speech tag. <br>\n",
    "XPOS: Language-specific part-of-speech tag; underscore if not available. <br>\n",
    "FEATS: List of morphological features from the universal feature inventory or from a defined language-specific extension; underscore if not available. <br>\n",
    "HEAD: Head of the current word, which is either a value of ID or zero (0). <br>\n",
    "DEPREL: Universal dependency relation to the HEAD (root iff HEAD = 0) or a defined language-specific subtype of one. <br>\n",
    "DEPS: Enhanced dependency graph in the form of a list of head-deprel pairs. <br>\n",
    "MISC: Any other annotation.\n",
    "\n",
    "The fields DEPS and MISC replace the obsolete fields PHEAD and PDEPREL of the CoNLL-X format. In addition, we have modified the usage of the ID, FORM, LEMMA, XPOS, FEATS and HEAD fields as explained below.\n",
    "\n",
    "The fields must additionally meet the following constraints:\n",
    "\n",
    "Fields must not be empty.\n",
    "Fields other than FORM, LEMMA, and MISC must not contain space characters.\n",
    "Underscore (_) is used to denote unspecified values in all fields except ID. Note that no format-level distinction is made for the rare cases where the FORM or LEMMA is the literal underscore â€“ processing in such cases is application-dependent. Further, in UD treebanks the UPOS, HEAD, and DEPREL columns are not allowed to be left unspecified except in multiword tokens, where all must be unspecified, and empty nodes, where UPOS is optional and HEAD and DEPREL must be unspecified. The enhanced DEPS annotation is optional in UD treebanks, but if it is provided, it must be provided for all sentences in the treebank. \"\n",
    "\n",
    "\n",
    "*** taken from https://universaldependencies.org/format.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieved header according to documentation\n",
    "conll_header = ['id', 'form', 'lemma', 'upos', 'xpos', 'feats', 'head', 'deprel', 'deps', 'misc']\n",
    "\n",
    "# header from lecture form 25.02.\n",
    "conll_header = ['id', 'form', 'lemma', 'upos', 'xpos', 'morph', 'head', 'dep', 'head_dep', 'space', 'predicate', 'label']\n",
    "\n",
    "conll_header_adapted = ['sentenceId', 'id', 'form', 'lemma', 'upos', 'xpos', 'morph', 'head', 'dep', 'head_dep', 'space', 'predicate', 'label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve longest line\n",
    "# -> required for the creation of the dataframe later\n",
    "def retrieveLength(path_to_file):\n",
    "    c = 0\n",
    "    max_line_length = -1\n",
    "    sentences = 0\n",
    "    tokens = 0\n",
    "    with open(path_to_file) as file:\n",
    "        for line in file:\n",
    "\n",
    "\n",
    "            if line.startswith('# text'):\n",
    "                sentences += 1\n",
    "            elif line.startswith('#') or line.startswith('\\n'):\n",
    "                pass\n",
    "            else:\n",
    "                values = line.split('\\t')\n",
    "                line_length = len(values)\n",
    "                if line_length > max_line_length:\n",
    "                    max_line_length = line_length\n",
    "\n",
    "                tokens += 1\n",
    "\n",
    "            c += 1   \n",
    "    \n",
    "    print(f'# Sentences in file: {sentences}')\n",
    "    print(f'# Tokens in file: {tokens}')\n",
    "    print(f'Maxium of columns in file: {max_line_length}')\n",
    "    \n",
    "    return max_line_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion into dataframe\n",
    "def createDataFrame(path_to_file, sentence_limit=None):\n",
    "\n",
    "    max_line_length = retrieveLength(path_to_file)\n",
    "    sentences = -1\n",
    "\n",
    "    ### create header\n",
    "    \n",
    "    # create empty dataframe with known columns and fillers for remaining collumns\n",
    "    headers_df = np.full(max_line_length + 1, np.str)  #  + 1 to add sentence column\n",
    "    \n",
    "    # add sentence column to header\n",
    "    #headers_df[1] = \n",
    "    \n",
    "    # add columns from identified columns\n",
    "    headers_df[:len(conll_header_adapted)] = conll_header_adapted\n",
    "    \n",
    "    # fill remaining column headers with '_'\n",
    "    headers_df[len(conll_header_adapted):] = '_'\n",
    "    \n",
    "    \n",
    "    ### create dataframe\n",
    "    df = pd.DataFrame(columns=headers_df)\n",
    "\n",
    "    \n",
    "    ### fill dataframe\n",
    "\n",
    "    # loop through file\n",
    "    with open(path_to_file) as file:\n",
    "        for line in file:\n",
    "\n",
    "            # pass all other lines\n",
    "            if line.startswith('# text'):\n",
    "                sentences += 1\n",
    "                \n",
    "            elif line.startswith('#') or line.startswith('\\n'):\n",
    "                pass\n",
    "            \n",
    "            # only go into token lines\n",
    "            else:\n",
    "                \n",
    "                # omit linebreaks from some lines\n",
    "                if line.endswith('\\n'):\n",
    "                    line = line.replace('\\n', '')\n",
    "                \n",
    "                # split input line\n",
    "                values = np.array(line.split('\\t'))\n",
    "\n",
    "                array  = np.full(max_line_length+1, np.str)\n",
    "                \n",
    "                # add sentenceId\n",
    "                array[0] = sentences\n",
    "                # add retrieved information from conll file\n",
    "                array[1:len(values)+1] = values\n",
    "                # fill remaining columns   !!** use np.nan ?! **!! \n",
    "                array[len(values)+1:] = '_'\n",
    "    \n",
    "                # create new entry\n",
    "                df_entry = pd.DataFrame(columns=headers_df, data=[array])\n",
    "\n",
    "                # concatenate to large dataframe\n",
    "                df = pd.concat([df, df_entry], axis = 0, ignore_index=True)\n",
    "\n",
    "            if type(sentence_limit) == int and sentences >= sentence_limit:\n",
    "                break\n",
    "                \n",
    "        print(f'\\n ## {len(df.sentenceId.unique())} sentences were added to dataframe.')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Sentences in file: 6\n",
      "# Tokens in file: 59\n",
      "Maxium of columns in file: 14\n",
      "\n",
      " ## 4 sentences were added to dataframe.\n",
      "added true value:  4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenceId</th>\n",
       "      <th>id</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>morph</th>\n",
       "      <th>head</th>\n",
       "      <th>dep</th>\n",
       "      <th>head_dep</th>\n",
       "      <th>space</th>\n",
       "      <th>predicate</th>\n",
       "      <th>label</th>\n",
       "      <th>_</th>\n",
       "      <th>_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>ca</td>\n",
       "      <td>can</td>\n",
       "      <td>AUX</td>\n",
       "      <td>MD</td>\n",
       "      <td>VerbForm=Fin</td>\n",
       "      <td>13</td>\n",
       "      <td>aux</td>\n",
       "      <td>13:aux</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>ARGM-MOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>n't</td>\n",
       "      <td>not</td>\n",
       "      <td>PART</td>\n",
       "      <td>RB</td>\n",
       "      <td>_</td>\n",
       "      <td>13</td>\n",
       "      <td>advmod</td>\n",
       "      <td>13:advmod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>ARGM-NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>beat</td>\n",
       "      <td>beat</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>VerbForm=Inf</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>0:root</td>\n",
       "      <td>_</td>\n",
       "      <td>beat.03</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>this</td>\n",
       "      <td>this</td>\n",
       "      <td>PRON</td>\n",
       "      <td>DT</td>\n",
       "      <td>Number=Sing|PronType=Dem</td>\n",
       "      <td>13</td>\n",
       "      <td>obj</td>\n",
       "      <td>13:obj</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>ARG1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>ok</td>\n",
       "      <td>ok</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>UH</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>0:root</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td></td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentenceId  id  form lemma  upos xpos                     morph head  \\\n",
       "27          2  11    ca   can   AUX   MD              VerbForm=Fin   13   \n",
       "28          2  12   n't   not  PART   RB                         _   13   \n",
       "29          2  13  beat  beat  VERB   VB              VerbForm=Inf    0   \n",
       "30          2  14  this  this  PRON   DT  Number=Sing|PronType=Dem   13   \n",
       "31          3   1    ok    ok  INTJ   UH                         _    0   \n",
       "\n",
       "       dep   head_dep          space predicate label  _         _  \n",
       "27     aux     13:aux  SpaceAfter=No         _     _  _  ARGM-MOD  \n",
       "28  advmod  13:advmod              _         _     _  _  ARGM-NEG  \n",
       "29    root     0:root              _   beat.03     _  _         V  \n",
       "30     obj     13:obj              _         _     _  _      ARG1  \n",
       "31    root     0:root              _         _        _         _  "
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call function with path to file and a integer that set the limit of sentences to include\n",
    "df = createDataFrame(path_example, 4)  # instead use (path_example, 2)  to only insert 2 sentences  \n",
    "\n",
    "print('added true value: ', len(df.sentenceId.unique()))\n",
    "df.tail(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 Âµs, sys: 0 ns, total: 3 Âµs\n",
      "Wall time: 4.77 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# call function with path to file and a integer that set the limit of sentences to include\n",
    "#df = createDataFrame(path_train, 1)\n",
    "\n",
    "#df.iloc[:,0:20].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# assign df to variable for this loop\\ndf = df  \\n\\n# creat dummy columns for each new variable\\n# use this format:  df['columnName'] = np.nan\\ndf['aFeature'] = np.nan\\n\\n# loop through sentences\\nfor s_id in df.sentenceId.unique():\\n    \\n    # filter for only this sentence\\n    df_sentence = df[df.sentenceId == s_id]\\n    \\n    # assign value to all features\\n    #df_sentence.aFeature = ... # uncomment\\n    \\n    # loop through lines if necesarry\\n    \\n    #display(df_sentence)\""
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Looping through sentences & assigning new values\n",
    "\n",
    "'''# assign df to variable for this loop\n",
    "df = df  \n",
    "\n",
    "# creat dummy columns for each new variable\n",
    "# use this format:  df['columnName'] = np.nan\n",
    "df['aFeature'] = np.nan\n",
    "\n",
    "# loop through sentences\n",
    "for s_id in df.sentenceId.unique():\n",
    "    \n",
    "    # filter for only this sentence\n",
    "    df_sentence = df[df.sentenceId == s_id]\n",
    "    \n",
    "    # assign value to all features\n",
    "    #df_sentence.aFeature = ... # uncomment\n",
    "    \n",
    "    # loop through lines if necesarry\n",
    "    \n",
    "    #display(df_sentence)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Sentences in file: 6\n",
      "# Tokens in file: 59\n",
      "Maxium of columns in file: 14\n",
      "\n",
      " ## 6 sentences were added to dataframe.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False,  True, False, False, False, False,\n",
       "       False,  True,  True, False, False, False, False, False, False,\n",
       "       False,  True,  True, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "        True,  True, False, False, False])"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### split datasets for predicate prediction\n",
    "\n",
    "\n",
    "# use test set \n",
    "df_full = createDataFrame(path_example, 6)\n",
    "\n",
    "# cutt of predicate and argument rows\n",
    "df_x = df_full.iloc[:,:11]\n",
    "\n",
    "df_y_true = df_full.iloc[:,11]\n",
    "y_true = np.array([True if x != '_' else False for x in df_y_true])\n",
    "\n",
    "# assign false prediction array for test purpose\n",
    "#y_true = [True, True, False, False,  # sentence 1\n",
    "#          True, True, False, False, False, False, True, True, False, False, False, False, False] #sentence 2\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenceId</th>\n",
       "      <th>id</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>morph</th>\n",
       "      <th>head</th>\n",
       "      <th>dep</th>\n",
       "      <th>head_dep</th>\n",
       "      <th>space</th>\n",
       "      <th>predicate</th>\n",
       "      <th>label</th>\n",
       "      <th>_</th>\n",
       "      <th>_</th>\n",
       "      <th>predicate_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Really</td>\n",
       "      <td>really</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>_</td>\n",
       "      <td>2</td>\n",
       "      <td>advmod</td>\n",
       "      <td>2:advmod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>ARGM-EXT</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>enjoyed</td>\n",
       "      <td>enjoy</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Mood=Ind|Tense=Past|VerbForm=Fin</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>0:root</td>\n",
       "      <td>_</td>\n",
       "      <td>enjoy.01</td>\n",
       "      <td>V</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Case=Nom|Gender=Neut|Number=Sing|Person=3|Pron...</td>\n",
       "      <td>2</td>\n",
       "      <td>obj</td>\n",
       "      <td>2:obj</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>_</td>\n",
       "      <td>ARG1</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>_</td>\n",
       "      <td>2</td>\n",
       "      <td>punct</td>\n",
       "      <td>2:punct</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Compare</td>\n",
       "      <td>compare</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>Tense=Past|VerbForm=Part</td>\n",
       "      <td>8</td>\n",
       "      <td>advcl</td>\n",
       "      <td>8:advcl</td>\n",
       "      <td>_</td>\n",
       "      <td>compare.01</td>\n",
       "      <td>V</td>\n",
       "      <td>_</td>\n",
       "      <td>ARGM-ADV</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentenceId id     form    lemma   upos xpos  \\\n",
       "0          0  1   Really   really    ADV   RB   \n",
       "1          0  2  enjoyed    enjoy   VERB  VBD   \n",
       "2          0  3       it       it   PRON  PRP   \n",
       "3          0  4        .        .  PUNCT    .   \n",
       "4          1  1  Compare  compare   VERB  VBN   \n",
       "\n",
       "                                               morph head     dep  head_dep  \\\n",
       "0                                                  _    2  advmod  2:advmod   \n",
       "1                   Mood=Ind|Tense=Past|VerbForm=Fin    0    root    0:root   \n",
       "2  Case=Nom|Gender=Neut|Number=Sing|Person=3|Pron...    2     obj     2:obj   \n",
       "3                                                  _    2   punct   2:punct   \n",
       "4                           Tense=Past|VerbForm=Part    8   advcl   8:advcl   \n",
       "\n",
       "           space   predicate     label  _         _  predicate_prediction  \n",
       "0              _           _  ARGM-EXT  _         _                 False  \n",
       "1              _    enjoy.01         V  _         _                  True  \n",
       "2  SpaceAfter=No           _      ARG1  _         _                 False  \n",
       "3              _           _         _  _         _                 False  \n",
       "4              _  compare.01         V  _  ARGM-ADV                  True  "
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "### helper functions for transformation of dataframe\n",
    "\n",
    "# helper function to combine predicate arrays\n",
    "# input value of predicate_gold and predicate_predicted. if either one is true, return true\n",
    "# -> applied via lambda function to each row in respective dataframe containing one sentence\n",
    "# -> goal is to have a boolean array that dictates the amount of needed repetitions of sentence  \n",
    "#    and at which index to look for predicate\n",
    "def findPredicateUnion(predicateGold, predicatePredicted):\n",
    "    if predicateGold != '_' or predicatePredicted == True:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### function to retrieve arguments\n",
    "\n",
    "def expandDataframe(input_df):\n",
    "\n",
    "    '''\n",
    "    input:  a dataframe containing the following columns:\n",
    "                ['sentenceId', \n",
    "                 'id', 'form', 'lemma', 'upos', 'xpos', 'morph', 'head', 'dep', 'head_dep', 'space', \n",
    "                 'predicate', 'label', '_', '_', ... '_', \n",
    "                 'predicate_prediction']\n",
    "\n",
    "                 -> note that \n",
    "                    - predicate_prediction has to be created beforehand\n",
    "                    - a variable amount of '_' columns is possible\n",
    "                    \n",
    "\n",
    "    output: the expanded dataframe dataframe containing the following columns\n",
    "                ['sentenceId', 'sentenceRepetition', \n",
    "                 'id', 'form', 'lemma', 'upos', 'xpos', 'morph', 'head', 'dep', 'head_dep', 'space',\n",
    "                 'predicate_prediction', 'label_ident_prediction', 'label_prediction',\n",
    "                 'predicate_gold', 'label_ident_gold', 'label_gold']\n",
    "\n",
    "    '''\n",
    "\n",
    "    ## hand over variables\n",
    "    df = input_df\n",
    "\n",
    "\n",
    "    ## prepare a dataframe to store all conversions in\n",
    "    # basic features\n",
    "    df_expanded = pd.DataFrame(columns=conll_header_adapted[:-2])\n",
    "    # + these four additional columns, we want to add\n",
    "    df_expanded['predicate_gold']       = False #np.nan\n",
    "    df_expanded['label_gold']           = np.nan\n",
    "    df_expanded['predicate_prediction'] = False #np.nan\n",
    "    df_expanded['sentenceRepetition']   = 0\n",
    "\n",
    "    df_expanded_columns = df_expanded.columns\n",
    "\n",
    "    ## do conversion\n",
    "\n",
    "    # loop through sentences\n",
    "    for s_id in df.sentenceId.unique():\n",
    "\n",
    "        # filter for only this sentence\n",
    "        df_sentence = df[df.sentenceId == s_id].copy()   # remove hardcoing of sentence 2 (equivalent to index 1) as example\n",
    "\n",
    "        # count rows for which predicate_gold is true (actually != '_') OR predicate_predicted is true\n",
    "        df_sentence['union_predicates_gold_predicted'] = df.apply(lambda x: findPredicateUnion(x.predicate, x.predicate_prediction), axis=1)\n",
    "\n",
    "\n",
    "        # return indices of rows with label True of the columns of the predicates\n",
    "        indices_union     = np.where(np.array(df_sentence.union_predicates_gold_predicted) == True)[0]\n",
    "        indices_gold      = np.where(np.array(df_sentence.predicate)                       != '_' )[0]\n",
    "        indices_predicted = np.where(np.array(df_sentence.predicate_prediction)            == True)[0]\n",
    "\n",
    "\n",
    "        #nr_of_predicates = df_sentence.union_predicates_gold_predicted[df_sentence.union_predicates_gold_predicted == True].count()\n",
    "        nr_of_predicates = len(indices_union)\n",
    "\n",
    "\n",
    "        # loop through nr_of_predicates\n",
    "        for i in range(nr_of_predicates):\n",
    "\n",
    "\n",
    "            # create new copy for working with within this repetition of sentence\n",
    "            df_sentence_repetition = df_sentence.copy()\n",
    "\n",
    "\n",
    "            ### fill values for new important columns\n",
    "\n",
    "            # id for repition of sentence to be able to loop through afterwards\n",
    "            df_sentence_repetition['sentenceRepetition']   = i\n",
    "\n",
    "\n",
    "            ## predicates\n",
    "\n",
    "            # fill predicate columns with False as default \n",
    "            # -> afterwards only replace that one specific row with True, which we look at in this repitition\n",
    "            predicate_array_gold   = np.full(len(df_sentence_repetition), False)\n",
    "            predicate_array_pred   = np.full(len(df_sentence_repetition), False)\n",
    "\n",
    "            # now replace respective index of predicate columns if it is also in the respective column\n",
    "            if indices_union[i] in indices_gold:\n",
    "                predicate_array_gold[indices_union[i]] = True\n",
    "            if indices_union[i] in indices_predicted:\n",
    "                predicate_array_pred[indices_union[i]] = True\n",
    "\n",
    "            # assign created arrays to dataframe\n",
    "            df_sentence_repetition['predicate_gold']       = predicate_array_gold\n",
    "            df_sentence_repetition['predicate_prediction'] = predicate_array_pred\n",
    "\n",
    "\n",
    "\n",
    "            ## labels\n",
    "\n",
    "            # -> transform labels from all label columns to this one column\n",
    "\n",
    "            # create filler array\n",
    "            label_array = np.full(len(df_sentence_repetition), '_')\n",
    "\n",
    "            # slice df_sentence\n",
    "            row = df_sentence.iloc[indices_union[i], :]\n",
    "            list_of_column_indices_with_V = np.where(np.array(row) == 'V')[0]\n",
    "\n",
    "            # sanity check -> columns found with V should be 1\n",
    "            if len(list_of_column_indices_with_V) == 1:\n",
    "\n",
    "                # do conversion\n",
    "\n",
    "                # find respective_label_column\n",
    "                respective_column_index = list_of_column_indices_with_V[0]\n",
    "\n",
    "                # retrieve column\n",
    "                respective_label_column = np.array(df_sentence.iloc[:, respective_column_index])\n",
    "\n",
    "                # replave 'V' label with '_'\n",
    "                respective_label_column[respective_label_column == 'V'] = '_'\n",
    "\n",
    "                # overwrite filler with retrieved labels\n",
    "                label_array = respective_label_column\n",
    "\n",
    "            # label_array remains only filled with '_' because no (coherent) labels could be found\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "            df_sentence_repetition['label_gold']        = label_array\n",
    "\n",
    "\n",
    "\n",
    "            ### \"postprocessing\"\n",
    "\n",
    "            # drop unneccessary columns \n",
    "            df_sentence_repetition = df_sentence_repetition.drop(labels=['_', 'label', 'predicate', 'union_predicates_gold_predicted'], axis=1)\n",
    "\n",
    "            # concatenate to large dataframe\n",
    "            df_expanded = pd.concat([df_expanded, df_sentence_repetition], axis = 0, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### insert general columns for later use\n",
    "\n",
    "    # for later insert of predicted label in in classification task\n",
    "    df_expanded['label_prediction']       = np.nan \n",
    "\n",
    "    # for prediction of label identification\n",
    "    df_expanded['label_ident_prediction'] = np.nan\n",
    "\n",
    "    # gold of label identification (true/false)\n",
    "    df_expanded['label_ident_gold']       = df_expanded.label_gold.apply(lambda x: True if x != '_' else False)\n",
    "\n",
    "    #reordering columns\n",
    "    df_expanded = df_expanded[['sentenceId', 'sentenceRepetition', \n",
    "                'id', 'form', 'lemma', 'upos', 'xpos', 'morph', 'head', 'dep', 'head_dep', 'space', \n",
    "                'predicate_prediction', 'label_ident_prediction', 'label_prediction', \n",
    "                'predicate_gold',       'label_ident_gold',       'label_gold']]\n",
    "        \n",
    "    \n",
    "    return df_expanded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning values for trying:\n",
    "df = df_full\n",
    "#df['prediction_true'] = df_full.prediction\n",
    "#df['label_true']      = np.nan # needs to be filled\n",
    "\n",
    "predicate_pred = y_true # for the moment, replace by predictions here\n",
    "\n",
    "\n",
    "## prepare df to work with\n",
    "# add predicate arry to df\n",
    "df['predicate_prediction'] = y_true\n",
    "\n",
    "new_df = expandDataframe(df)\n",
    "\n",
    "new_df.to_csv('../data/intermediate/expandedDataframe_smallExample', index=False )#, index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenceId</th>\n",
       "      <th>sentenceRepetition</th>\n",
       "      <th>id</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>morph</th>\n",
       "      <th>head</th>\n",
       "      <th>dep</th>\n",
       "      <th>head_dep</th>\n",
       "      <th>space</th>\n",
       "      <th>predicate_prediction</th>\n",
       "      <th>label_ident_prediction</th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>predicate_gold</th>\n",
       "      <th>label_ident_gold</th>\n",
       "      <th>label_gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Really</td>\n",
       "      <td>really</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>_</td>\n",
       "      <td>2</td>\n",
       "      <td>advmod</td>\n",
       "      <td>2:advmod</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ARGM-EXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>enjoyed</td>\n",
       "      <td>enjoy</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Mood=Ind|Tense=Past|VerbForm=Fin</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>0:root</td>\n",
       "      <td>_</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>Case=Nom|Gender=Neut|Number=Sing|Person=3|Pron...</td>\n",
       "      <td>2</td>\n",
       "      <td>obj</td>\n",
       "      <td>2:obj</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ARG1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>_</td>\n",
       "      <td>2</td>\n",
       "      <td>punct</td>\n",
       "      <td>2:punct</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Compare</td>\n",
       "      <td>compare</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>Tense=Past|VerbForm=Part</td>\n",
       "      <td>8</td>\n",
       "      <td>advcl</td>\n",
       "      <td>8:advcl</td>\n",
       "      <td>_</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentenceId  sentenceRepetition  id     form    lemma   upos xpos  \\\n",
       "0           0                   0   1   Really   really    ADV   RB   \n",
       "1           0                   0   2  enjoyed    enjoy   VERB  VBD   \n",
       "2           0                   0   3       it       it   PRON  PRP   \n",
       "3           0                   0   4        .        .  PUNCT    .   \n",
       "4           1                   0   1  Compare  compare   VERB  VBN   \n",
       "\n",
       "                                               morph  head     dep  head_dep  \\\n",
       "0                                                  _     2  advmod  2:advmod   \n",
       "1                   Mood=Ind|Tense=Past|VerbForm=Fin     0    root    0:root   \n",
       "2  Case=Nom|Gender=Neut|Number=Sing|Person=3|Pron...     2     obj     2:obj   \n",
       "3                                                  _     2   punct   2:punct   \n",
       "4                           Tense=Past|VerbForm=Part     8   advcl   8:advcl   \n",
       "\n",
       "           space  predicate_prediction  label_ident_prediction  \\\n",
       "0              _                 False                     NaN   \n",
       "1              _                  True                     NaN   \n",
       "2  SpaceAfter=No                 False                     NaN   \n",
       "3              _                 False                     NaN   \n",
       "4              _                  True                     NaN   \n",
       "\n",
       "   label_prediction  predicate_gold  label_ident_gold label_gold  \n",
       "0               NaN           False              True   ARGM-EXT  \n",
       "1               NaN            True             False          _  \n",
       "2               NaN           False              True       ARG1  \n",
       "3               NaN           False             False          _  \n",
       "4               NaN            True             False          _  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_read = pd.read_csv('../data/intermediate/expandedDataframe_smallExample')\n",
    "\n",
    "# head\n",
    "display(df_read.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentenceId</th>\n",
       "      <th>sentenceRepetition</th>\n",
       "      <th>id</th>\n",
       "      <th>form</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>morph</th>\n",
       "      <th>head</th>\n",
       "      <th>dep</th>\n",
       "      <th>head_dep</th>\n",
       "      <th>space</th>\n",
       "      <th>predicate_prediction</th>\n",
       "      <th>label_ident_prediction</th>\n",
       "      <th>label_prediction</th>\n",
       "      <th>predicate_gold</th>\n",
       "      <th>label_ident_gold</th>\n",
       "      <th>label_gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>One</td>\n",
       "      <td>one</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>NumType=Card</td>\n",
       "      <td>5</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>5:nsubj</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ARG0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>case</td>\n",
       "      <td>4:case</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Definite=Def|PronType=Art</td>\n",
       "      <td>4</td>\n",
       "      <td>det</td>\n",
       "      <td>4:det</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>pictures</td>\n",
       "      <td>picture</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Number=Plur</td>\n",
       "      <td>1</td>\n",
       "      <td>nmod</td>\n",
       "      <td>1:nmod:of</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>shows</td>\n",
       "      <td>show</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>0:root</td>\n",
       "      <td>_</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Definite=Ind|PronType=Art</td>\n",
       "      <td>7</td>\n",
       "      <td>det</td>\n",
       "      <td>7:det</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>flag</td>\n",
       "      <td>flag</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>5</td>\n",
       "      <td>obj</td>\n",
       "      <td>5:obj|10:nsubj:pass</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ARG1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WDT</td>\n",
       "      <td>PronType=Rel</td>\n",
       "      <td>10</td>\n",
       "      <td>nsubj:pass</td>\n",
       "      <td>7:ref</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>was</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbF...</td>\n",
       "      <td>10</td>\n",
       "      <td>aux:pass</td>\n",
       "      <td>10:aux:pass</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>found</td>\n",
       "      <td>find</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>Tense=Past|VerbForm=Part|Voice=Pass</td>\n",
       "      <td>7</td>\n",
       "      <td>acl:relcl</td>\n",
       "      <td>7:acl:relcl</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>12</td>\n",
       "      <td>case</td>\n",
       "      <td>12:case</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>Fallujah</td>\n",
       "      <td>Fallujah</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>10</td>\n",
       "      <td>obl</td>\n",
       "      <td>10:obl:in</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>_</td>\n",
       "      <td>5</td>\n",
       "      <td>punct</td>\n",
       "      <td>5:punct</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>One</td>\n",
       "      <td>one</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>NumType=Card</td>\n",
       "      <td>5</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>5:nsubj</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>case</td>\n",
       "      <td>4:case</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Definite=Def|PronType=Art</td>\n",
       "      <td>4</td>\n",
       "      <td>det</td>\n",
       "      <td>4:det</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>pictures</td>\n",
       "      <td>picture</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Number=Plur</td>\n",
       "      <td>1</td>\n",
       "      <td>nmod</td>\n",
       "      <td>1:nmod:of</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>shows</td>\n",
       "      <td>show</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>0:root</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Definite=Ind|PronType=Art</td>\n",
       "      <td>7</td>\n",
       "      <td>det</td>\n",
       "      <td>7:det</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>flag</td>\n",
       "      <td>flag</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>5</td>\n",
       "      <td>obj</td>\n",
       "      <td>5:obj|10:nsubj:pass</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WDT</td>\n",
       "      <td>PronType=Rel</td>\n",
       "      <td>10</td>\n",
       "      <td>nsubj:pass</td>\n",
       "      <td>7:ref</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>was</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbF...</td>\n",
       "      <td>10</td>\n",
       "      <td>aux:pass</td>\n",
       "      <td>10:aux:pass</td>\n",
       "      <td>_</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>found</td>\n",
       "      <td>find</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>Tense=Past|VerbForm=Part|Voice=Pass</td>\n",
       "      <td>7</td>\n",
       "      <td>acl:relcl</td>\n",
       "      <td>7:acl:relcl</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>12</td>\n",
       "      <td>case</td>\n",
       "      <td>12:case</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Fallujah</td>\n",
       "      <td>Fallujah</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>10</td>\n",
       "      <td>obl</td>\n",
       "      <td>10:obl:in</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>_</td>\n",
       "      <td>5</td>\n",
       "      <td>punct</td>\n",
       "      <td>5:punct</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>One</td>\n",
       "      <td>one</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>NumType=Card</td>\n",
       "      <td>5</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>5:nsubj</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>4</td>\n",
       "      <td>case</td>\n",
       "      <td>4:case</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Definite=Def|PronType=Art</td>\n",
       "      <td>4</td>\n",
       "      <td>det</td>\n",
       "      <td>4:det</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>pictures</td>\n",
       "      <td>picture</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Number=Plur</td>\n",
       "      <td>1</td>\n",
       "      <td>nmod</td>\n",
       "      <td>1:nmod:of</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>shows</td>\n",
       "      <td>show</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>0:root</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Definite=Ind|PronType=Art</td>\n",
       "      <td>7</td>\n",
       "      <td>det</td>\n",
       "      <td>7:det</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>flag</td>\n",
       "      <td>flag</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>5</td>\n",
       "      <td>obj</td>\n",
       "      <td>5:obj|10:nsubj:pass</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ARG1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WDT</td>\n",
       "      <td>PronType=Rel</td>\n",
       "      <td>10</td>\n",
       "      <td>nsubj:pass</td>\n",
       "      <td>7:ref</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>R-ARG1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>was</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbF...</td>\n",
       "      <td>10</td>\n",
       "      <td>aux:pass</td>\n",
       "      <td>10:aux:pass</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>found</td>\n",
       "      <td>find</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>Tense=Past|VerbForm=Part|Voice=Pass</td>\n",
       "      <td>7</td>\n",
       "      <td>acl:relcl</td>\n",
       "      <td>7:acl:relcl</td>\n",
       "      <td>_</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>12</td>\n",
       "      <td>case</td>\n",
       "      <td>12:case</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>Fallujah</td>\n",
       "      <td>Fallujah</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>10</td>\n",
       "      <td>obl</td>\n",
       "      <td>10:obl:in</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ARGM-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>_</td>\n",
       "      <td>5</td>\n",
       "      <td>punct</td>\n",
       "      <td>5:punct</td>\n",
       "      <td>_</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentenceId  sentenceRepetition  id      form     lemma   upos xpos  \\\n",
       "127           5                   0   1       One       one    NUM   CD   \n",
       "128           5                   0   2        of        of    ADP   IN   \n",
       "129           5                   0   3       the       the    DET   DT   \n",
       "130           5                   0   4  pictures   picture   NOUN  NNS   \n",
       "131           5                   0   5     shows      show   VERB  VBZ   \n",
       "132           5                   0   6         a         a    DET   DT   \n",
       "133           5                   0   7      flag      flag   NOUN   NN   \n",
       "134           5                   0   8      that      that   PRON  WDT   \n",
       "135           5                   0   9       was        be    AUX  VBD   \n",
       "136           5                   0  10     found      find   VERB  VBN   \n",
       "137           5                   0  11        in        in    ADP   IN   \n",
       "138           5                   0  12  Fallujah  Fallujah  PROPN  NNP   \n",
       "139           5                   0  13         .         .  PUNCT    .   \n",
       "140           5                   1   1       One       one    NUM   CD   \n",
       "141           5                   1   2        of        of    ADP   IN   \n",
       "142           5                   1   3       the       the    DET   DT   \n",
       "143           5                   1   4  pictures   picture   NOUN  NNS   \n",
       "144           5                   1   5     shows      show   VERB  VBZ   \n",
       "145           5                   1   6         a         a    DET   DT   \n",
       "146           5                   1   7      flag      flag   NOUN   NN   \n",
       "147           5                   1   8      that      that   PRON  WDT   \n",
       "148           5                   1   9       was        be    AUX  VBD   \n",
       "149           5                   1  10     found      find   VERB  VBN   \n",
       "150           5                   1  11        in        in    ADP   IN   \n",
       "151           5                   1  12  Fallujah  Fallujah  PROPN  NNP   \n",
       "152           5                   1  13         .         .  PUNCT    .   \n",
       "153           5                   2   1       One       one    NUM   CD   \n",
       "154           5                   2   2        of        of    ADP   IN   \n",
       "155           5                   2   3       the       the    DET   DT   \n",
       "156           5                   2   4  pictures   picture   NOUN  NNS   \n",
       "157           5                   2   5     shows      show   VERB  VBZ   \n",
       "158           5                   2   6         a         a    DET   DT   \n",
       "159           5                   2   7      flag      flag   NOUN   NN   \n",
       "160           5                   2   8      that      that   PRON  WDT   \n",
       "161           5                   2   9       was        be    AUX  VBD   \n",
       "162           5                   2  10     found      find   VERB  VBN   \n",
       "163           5                   2  11        in        in    ADP   IN   \n",
       "164           5                   2  12  Fallujah  Fallujah  PROPN  NNP   \n",
       "165           5                   2  13         .         .  PUNCT    .   \n",
       "\n",
       "                                                 morph  head         dep  \\\n",
       "127                                       NumType=Card     5       nsubj   \n",
       "128                                                  _     4        case   \n",
       "129                          Definite=Def|PronType=Art     4         det   \n",
       "130                                        Number=Plur     1        nmod   \n",
       "131  Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...     0        root   \n",
       "132                          Definite=Ind|PronType=Art     7         det   \n",
       "133                                        Number=Sing     5         obj   \n",
       "134                                       PronType=Rel    10  nsubj:pass   \n",
       "135  Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbF...    10    aux:pass   \n",
       "136                Tense=Past|VerbForm=Part|Voice=Pass     7   acl:relcl   \n",
       "137                                                  _    12        case   \n",
       "138                                        Number=Sing    10         obl   \n",
       "139                                                  _     5       punct   \n",
       "140                                       NumType=Card     5       nsubj   \n",
       "141                                                  _     4        case   \n",
       "142                          Definite=Def|PronType=Art     4         det   \n",
       "143                                        Number=Plur     1        nmod   \n",
       "144  Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...     0        root   \n",
       "145                          Definite=Ind|PronType=Art     7         det   \n",
       "146                                        Number=Sing     5         obj   \n",
       "147                                       PronType=Rel    10  nsubj:pass   \n",
       "148  Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbF...    10    aux:pass   \n",
       "149                Tense=Past|VerbForm=Part|Voice=Pass     7   acl:relcl   \n",
       "150                                                  _    12        case   \n",
       "151                                        Number=Sing    10         obl   \n",
       "152                                                  _     5       punct   \n",
       "153                                       NumType=Card     5       nsubj   \n",
       "154                                                  _     4        case   \n",
       "155                          Definite=Def|PronType=Art     4         det   \n",
       "156                                        Number=Plur     1        nmod   \n",
       "157  Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...     0        root   \n",
       "158                          Definite=Ind|PronType=Art     7         det   \n",
       "159                                        Number=Sing     5         obj   \n",
       "160                                       PronType=Rel    10  nsubj:pass   \n",
       "161  Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbF...    10    aux:pass   \n",
       "162                Tense=Past|VerbForm=Part|Voice=Pass     7   acl:relcl   \n",
       "163                                                  _    12        case   \n",
       "164                                        Number=Sing    10         obl   \n",
       "165                                                  _     5       punct   \n",
       "\n",
       "                head_dep          space  predicate_prediction  \\\n",
       "127              5:nsubj              _                 False   \n",
       "128               4:case              _                 False   \n",
       "129                4:det              _                 False   \n",
       "130            1:nmod:of              _                 False   \n",
       "131               0:root              _                  True   \n",
       "132                7:det              _                 False   \n",
       "133  5:obj|10:nsubj:pass              _                 False   \n",
       "134                7:ref              _                 False   \n",
       "135          10:aux:pass              _                 False   \n",
       "136          7:acl:relcl              _                 False   \n",
       "137              12:case              _                 False   \n",
       "138            10:obl:in  SpaceAfter=No                 False   \n",
       "139              5:punct              _                 False   \n",
       "140              5:nsubj              _                 False   \n",
       "141               4:case              _                 False   \n",
       "142                4:det              _                 False   \n",
       "143            1:nmod:of              _                 False   \n",
       "144               0:root              _                 False   \n",
       "145                7:det              _                 False   \n",
       "146  5:obj|10:nsubj:pass              _                 False   \n",
       "147                7:ref              _                 False   \n",
       "148          10:aux:pass              _                  True   \n",
       "149          7:acl:relcl              _                 False   \n",
       "150              12:case              _                 False   \n",
       "151            10:obl:in  SpaceAfter=No                 False   \n",
       "152              5:punct              _                 False   \n",
       "153              5:nsubj              _                 False   \n",
       "154               4:case              _                 False   \n",
       "155                4:det              _                 False   \n",
       "156            1:nmod:of              _                 False   \n",
       "157               0:root              _                 False   \n",
       "158                7:det              _                 False   \n",
       "159  5:obj|10:nsubj:pass              _                 False   \n",
       "160                7:ref              _                 False   \n",
       "161          10:aux:pass              _                 False   \n",
       "162          7:acl:relcl              _                  True   \n",
       "163              12:case              _                 False   \n",
       "164            10:obl:in  SpaceAfter=No                 False   \n",
       "165              5:punct              _                 False   \n",
       "\n",
       "     label_ident_prediction  label_prediction  predicate_gold  \\\n",
       "127                     NaN               NaN           False   \n",
       "128                     NaN               NaN           False   \n",
       "129                     NaN               NaN           False   \n",
       "130                     NaN               NaN           False   \n",
       "131                     NaN               NaN            True   \n",
       "132                     NaN               NaN           False   \n",
       "133                     NaN               NaN           False   \n",
       "134                     NaN               NaN           False   \n",
       "135                     NaN               NaN           False   \n",
       "136                     NaN               NaN           False   \n",
       "137                     NaN               NaN           False   \n",
       "138                     NaN               NaN           False   \n",
       "139                     NaN               NaN           False   \n",
       "140                     NaN               NaN           False   \n",
       "141                     NaN               NaN           False   \n",
       "142                     NaN               NaN           False   \n",
       "143                     NaN               NaN           False   \n",
       "144                     NaN               NaN           False   \n",
       "145                     NaN               NaN           False   \n",
       "146                     NaN               NaN           False   \n",
       "147                     NaN               NaN           False   \n",
       "148                     NaN               NaN            True   \n",
       "149                     NaN               NaN           False   \n",
       "150                     NaN               NaN           False   \n",
       "151                     NaN               NaN           False   \n",
       "152                     NaN               NaN           False   \n",
       "153                     NaN               NaN           False   \n",
       "154                     NaN               NaN           False   \n",
       "155                     NaN               NaN           False   \n",
       "156                     NaN               NaN           False   \n",
       "157                     NaN               NaN           False   \n",
       "158                     NaN               NaN           False   \n",
       "159                     NaN               NaN           False   \n",
       "160                     NaN               NaN           False   \n",
       "161                     NaN               NaN           False   \n",
       "162                     NaN               NaN            True   \n",
       "163                     NaN               NaN           False   \n",
       "164                     NaN               NaN           False   \n",
       "165                     NaN               NaN           False   \n",
       "\n",
       "     label_ident_gold label_gold  \n",
       "127              True       ARG0  \n",
       "128             False          _  \n",
       "129             False          _  \n",
       "130             False          _  \n",
       "131             False          _  \n",
       "132             False          _  \n",
       "133              True       ARG1  \n",
       "134             False          _  \n",
       "135             False          _  \n",
       "136             False          _  \n",
       "137             False          _  \n",
       "138             False          _  \n",
       "139             False          _  \n",
       "140             False          _  \n",
       "141             False          _  \n",
       "142             False          _  \n",
       "143             False          _  \n",
       "144             False          _  \n",
       "145             False          _  \n",
       "146             False          _  \n",
       "147             False          _  \n",
       "148             False          _  \n",
       "149             False          _  \n",
       "150             False          _  \n",
       "151             False          _  \n",
       "152             False          _  \n",
       "153             False          _  \n",
       "154             False          _  \n",
       "155             False          _  \n",
       "156             False          _  \n",
       "157             False          _  \n",
       "158             False          _  \n",
       "159              True       ARG1  \n",
       "160              True     R-ARG1  \n",
       "161             False          _  \n",
       "162             False          _  \n",
       "163             False          _  \n",
       "164              True   ARGM-LOC  \n",
       "165             False          _  "
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passive sentence\n",
    "df_read.tail(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
